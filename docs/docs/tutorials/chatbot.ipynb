{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "cThDJhq6_ENE"
      },
      "source": [
        "---\n",
        "sidebar_position: 1\n",
        "keywords: [conversationchain]\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZnkeTix_ENF"
      },
      "source": [
        "# Build a Chatbot构建聊天机器人"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEQHW8jI_ENG"
      },
      "source": [
        ":::note注意\n",
        "\n",
        "This tutorial previously used the [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) abstraction. You can access that version of the documentation in the [v0.2 docs](https://python.langchain.com/v0.2/docs/tutorials/chatbot/).\n",
        "\n",
        "本教程之前使用了 RunnableWithMessageHistory 抽象。您可以在 v0.2 文档中访问该版本的文档。\n",
        "\n",
        "As of the v0.3 release of LangChain, we recommend that LangChain users take advantage of [LangGraph persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/) to incorporate `memory` into new LangChain applications.\n",
        "\n",
        "自 LangChain v0.3 版本发布以来，我们建议 LangChain 用户利用 LangGraph 持久化功能，将 memory 集成到新的 LangChain 应用程序中。\n",
        "\n",
        "If your code is already relying on `RunnableWithMessageHistory` or `BaseChatMessageHistory`, you do **not** need to make any changes. We do not plan on deprecating this functionality in the near future as it works for simple chat applications and any code that uses `RunnableWithMessageHistory` will continue to work as expected.\n",
        "\n",
        "如果您的代码已经依赖于 RunnableWithMessageHistory 或 BaseChatMessageHistory ，您无需进行任何更改。我们不打算在近期内弃用此功能，因为它适用于简单的聊天应用，并且任何使用 RunnableWithMessageHistory 的代码将继续按预期工作。\n",
        "\n",
        "Please see [How to migrate to LangGraph Memory](/docs/versions/migrating_memory/) for more details.\n",
        "\n",
        "请参阅如何迁移到 LangGraph Memory 以获取更多详细信息。\n",
        ":::\n",
        "\n",
        "## Overview概述\n",
        "\n",
        "我们将介绍一个如何设计和实现由LLM驱动的聊天机器人的示例。这个聊天机器人将能够进行对话并记住与[聊天模型](/docs/concepts/chat_models)的先前交互。\n",
        "\n",
        "注意，我们构建的聊天机器人将仅使用语言模型进行对话。你可能还想知道其他几个相关概念：\n",
        "\n",
        "- [Conversational RAG](/docs/tutorials/qa_chat_history)对话式 RAG: 通过外部数据源实现聊天机器人体验\n",
        "- [Agents](/docs/tutorials/agents): 构建能够执行操作的聊天机器人\n",
        "\n",
        "本教程将涵盖基础知识，这将有助于那些更高级的主题，但如果你愿意，也可以直接跳到那里。\n",
        "\n",
        "## Setup设置\n",
        "\n",
        "### Jupyter Notebook\n",
        "\n",
        "This guide (and most of the other guides in the documentation) uses [Jupyter notebooks](https://jupyter.org/) and assumes the reader is as well. Jupyter notebooks are perfect for learning how to work with LLM systems because oftentimes things can go wrong (unexpected output, API down, etc) and going through guides in an interactive environment is a great way to better understand them.\n",
        "\n",
        "本指南（以及文档中的大多数其他指南）使用 Jupyter 笔记本，并假设读者也是如此。Jupyter 笔记本非常适合学习如何与LLM系统一起工作，因为事情有时可能会出错（意外输出、API 故障等），在交互式环境中学习指南是更好地理解它们的好方法。\n",
        "\n",
        "This and other tutorials are perhaps most conveniently run in a Jupyter notebook. See [here](https://jupyter.org/install) for instructions on how to install.\n",
        "\n",
        "本教程和其他教程可能最方便在 Jupyter 笔记本中运行。有关安装说明，请参阅此处。\n",
        "\n",
        "### Installation 安装\n",
        "\n",
        "在本教程中，我们需要 `langchain-core` 和 `langgraph` 。本指南需要 `langgraph >= 0.2.28` 。\n",
        "\n",
        "import Tabs from '@theme/Tabs';\n",
        "import TabItem from '@theme/TabItem';\n",
        "import CodeBlock from \"@theme/CodeBlock\";\n",
        "\n",
        "<Tabs>\n",
        "  <TabItem value=\"pip\" label=\"Pip\" default>\n",
        "    <CodeBlock language=\"bash\">pip install langchain-core langgraph>0.2.27</CodeBlock>\n",
        "  </TabItem>\n",
        "  <TabItem value=\"conda\" label=\"Conda\">\n",
        "    <CodeBlock language=\"bash\">conda install langchain-core langgraph>0.2.27 -c conda-forge</CodeBlock>\n",
        "  </TabItem>\n",
        "</Tabs>\n",
        "\n",
        "\n",
        "\n",
        "查看更多详情，请参阅我们的[安装指南](/docs/how_to/installation)。\n",
        "\n",
        "### LangSmith\n",
        "\n",
        "您使用 LangChain 构建的许多应用程序将包含多个步骤和多个LLM调用的调用。随着这些应用程序变得越来越复杂，能够检查您的链或代理内部到底发生了什么变得至关重要。最好的方法是使用[LangSmith](https://smith.langchain.com)。\n",
        "\n",
        "在您通过上述链接注册后，请确保设置环境变量以开始记录跟踪：\n",
        "\n",
        "```shell\n",
        "export LANGSMITH_TRACING=\"true\"\n",
        "export LANGSMITH_API_KEY=\"...\"\n",
        "```\n",
        "\n",
        "或者，如果在笔记本中，你可以这样设置它们：\n",
        "\n",
        "```python\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
        "```\n",
        "\n",
        "## Quickstart快速入门\n",
        "\n",
        "首先，让我们学习如何单独使用语言模型。LangChain 支持许多不同的语言模型，您可以选择其中一个来使用！\n",
        "\n",
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs overrideParams={{openai: {model: \"gpt-4o-mini\"}}} />\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-core langgraph\n",
        "!pip install -qU \"langchain[openai]\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "U724DeNPBSyS",
        "outputId": "93082e21-66b7-4a46-e4ee-ddd67cda805f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.47)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.10.6)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.7-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.59-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.20-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.23-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.7-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.59-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.20 langgraph-checkpoint-2.0.23 langgraph-prebuilt-0.1.7 langgraph-sdk-0.1.59 ormsgpack-1.9.0 xxhash-3.5.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.1/420.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[groq]\""
      ],
      "metadata": {
        "id": "McGSPChuCSUl",
        "outputId": "08eb34ef-2fc4-4a95-cba7-0a10b83124d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VhVwbTiV_ENH"
      },
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "  # os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
        "  os.environ[\"GROQ_API_KEY\"] = userdata.get('groq')\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx0YO-yg_ENJ"
      },
      "source": [
        "Let's first use the model directly. `ChatModel`s are instances of LangChain \"Runnables\", which means they expose a standard interface for interacting with them. To just simply call the model, we can pass in a list of messages to the `.invoke` method.\n",
        "\n",
        "首先直接使用模型。 ChatModel 是 LangChain 的 \"Runnables\" 实例，这意味着它们提供了一个标准接口来与之交互。要简单地调用模型，我们可以向 .invoke 方法传递一个消息列表。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wUf78655_ENJ",
        "outputId": "5928b036-c72c-4302-fdab-42afbebd7e7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hi Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 15, 'total_tokens': 41, 'completion_time': 0.021666667, 'prompt_time': 0.003126259, 'queue_time': 0.139656101, 'total_time': 0.024792926}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-7e183507-2a1d-43ab-962d-f0d77ca8592d-0', usage_metadata={'input_tokens': 15, 'output_tokens': 26, 'total_tokens': 41})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlj_ee98_ENK"
      },
      "source": [
        "该模型本身没有任何状态概念。例如，如果你问一个后续问题："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qRBJpZ2k_ENL",
        "outputId": "b14f42a3-d46c-4e0a-eaa9-f9f3a2e20edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I apologize, but I'm a large language model, I don't have the ability to know your name or any personal information about you. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations. If you'd like to share your name with me, I'd be happy to learn it!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 15, 'total_tokens': 86, 'completion_time': 0.059166667, 'prompt_time': 0.002968449, 'queue_time': 0.30243658500000004, 'total_time': 0.062135116}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-ccc411e0-5c67-483b-bc48-8837e7ea7c64-0', usage_metadata={'input_tokens': 15, 'output_tokens': 71, 'total_tokens': 86})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model.invoke([HumanMessage(content=\"What's my name?\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7MRuLHo_ENL"
      },
      "source": [
        "让我们看看 LangSmith 跟踪示例 [LangSmith trace](https://smith.langchain.com/public/5c21cb92-2814-4119-bae9-d02b8db577ac/r)\n",
        "\n",
        "我们可以看到它没有将之前的对话轮次转化为上下文，也无法回答问题。\n",
        "这导致聊天机器人体验极差！\n",
        "\n",
        "To get around this, we need to pass the entire [conversation history](/docs/concepts/chat_history) into the model. Let's see what happens when we do that:\n",
        "\n",
        "为了解决这个问题，我们需要将整个对话历史传递给模型。让我们看看这样做会发生什么："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PcCOzXwc_ENL",
        "outputId": "2505e30a-36e8-4785-c481-684c6f95de96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Your name is Bob!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 40, 'total_tokens': 46, 'completion_time': 0.005, 'prompt_time': 0.007692006, 'queue_time': 0.017407112, 'total_time': 0.012692006}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_dadc9d6142', 'finish_reason': 'stop', 'logprobs': None}, id='run-92a6adde-0a15-4454-b665-e1b12a9ffe33-0', usage_metadata={'input_tokens': 40, 'output_tokens': 6, 'total_tokens': 46})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
        "        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
        "        HumanMessage(content=\"What's my name?\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pznCMQTq_ENL"
      },
      "source": [
        "现在我们可以看到我们得到了一个很好的响应！\n",
        "\n",
        "这是支撑聊天机器人进行对话交互的基本理念。\n",
        "那么我们如何最好地实现这一点呢？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXI39QDe_ENM"
      },
      "source": [
        "## Message persistence消息持久化\n",
        "\n",
        "[LangGraph](https://langchain-ai.github.io/langgraph/) 实现了一个内置的持久化层，使其非常适合支持多个对话轮次的聊天应用。\n",
        "\n",
        "将我们的聊天模型封装在一个最小的 LangGraph 应用程序中，使我们能够自动持久化消息历史，简化多轮应用的开发。\n",
        "\n",
        "LangGraph comes with a simple in-memory checkpointer, which we use below. See its [documentation](https://langchain-ai.github.io/langgraph/concepts/persistence/) for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).\n",
        "\n",
        "LangGraph 附带一个简单的内存检查点器，我们下面会用到。请参阅其文档以获取更多详细信息，包括如何使用不同的持久化后端（例如 SQLite 或 Postgres）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RL524OIc_ENM"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: MessagesState):\n",
        "    response = model.invoke(state[\"messages\"])\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "# Define the (single) node in the graph\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "# Add memory\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRIOMrZc_ENM"
      },
      "source": [
        "We now need to create a `config` that we pass into the runnable every time. This config contains information that is not part of the input directly, but is still useful. In this case, we want to include a `thread_id`. This should look like:\n",
        "\n",
        "我们现在需要创建一个 config ，每次运行可执行文件时都要传递进去。这个配置包含了一些不是直接输入部分的信息，但仍然很有用。在这种情况下，我们想要包含一个 thread_id 。这应该看起来像："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0EmoBdAQ_ENM"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBGpim2_ENM"
      },
      "source": [
        "这使我们能够使用单个应用程序支持多个对话线程，这是当您的应用程序有多个用户时的常见需求。\n",
        "\n",
        "我们可以调用该应用程序："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DAms8Fm__ENM",
        "outputId": "88d2db1f-ef49-4644-fe65-63b02ae02be5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Bob, you're really friendly! I think we've had a few \"Hi, I'm Bob\"s already! Let's try to break the ice, shall we? I'll ask you a question: What's your favorite thing to do on a sunny Saturday morning?\n"
          ]
        }
      ],
      "source": [
        "query = \"Hi! I'm Bob.\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[\"messages\"]"
      ],
      "metadata": {
        "id": "bmifoJPhLfFn",
        "outputId": "702893bc-8960-4456-81b3-e565137e3199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"Hi! I'm Bob.\", additional_kwargs={}, response_metadata={}, id='f21367a4-16a5-45a4-a3ef-6fc97a08d75f'),\n",
              " AIMessage(content='Hi Bob! Nice to meet you! Is there something I can help you with or would you like to chat?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 16, 'total_tokens': 40, 'completion_time': 0.02, 'prompt_time': 0.00241603, 'queue_time': 0.019515349, 'total_time': 0.02241603}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-687dedc0-9675-4669-b4df-5e7316126e77-0', usage_metadata={'input_tokens': 16, 'output_tokens': 24, 'total_tokens': 40}),\n",
              " HumanMessage(content=\"Hi! I'm Bob.\", additional_kwargs={}, response_metadata={}, id='bf3f95f6-08f6-408c-8c75-edd215641fde'),\n",
              " AIMessage(content=\"Hi Bob! It looks like you said hello again! Don't worry, I'm here to chat and help if you need it. What's on your mind today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 55, 'total_tokens': 90, 'completion_time': 0.029166667, 'prompt_time': 0.007461622, 'queue_time': 0.020858356999999998, 'total_time': 0.036628289}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-30c71d7b-2f53-4864-ab42-b2dede02ec32-0', usage_metadata={'input_tokens': 55, 'output_tokens': 35, 'total_tokens': 90}),\n",
              " HumanMessage(content=\"Hi! I'm Bob.\", additional_kwargs={}, response_metadata={}, id='bd05efd0-5bb6-4c21-8476-b425efe40cb6'),\n",
              " AIMessage(content=\"Bob, you're a friendly guy, aren't you? Hi again! I'm here to chat, but maybe we can try to think of something new to talk about, hmm? What are you interested in? Do you have a favorite hobby or topic you'd like to discuss?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 105, 'total_tokens': 163, 'completion_time': 0.048333333, 'prompt_time': 0.013651029, 'queue_time': 0.022182930999999996, 'total_time': 0.061984362}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-a5c0f895-106e-4338-841b-586626a82f0b-0', usage_metadata={'input_tokens': 105, 'output_tokens': 58, 'total_tokens': 163}),\n",
              " HumanMessage(content=\"Hi! I'm Bob.\", additional_kwargs={}, response_metadata={}, id='33dd062b-76c6-4061-b43b-ecfb8c3ca1c5'),\n",
              " AIMessage(content='Bob, you\\'re really friendly! I think we\\'ve had a few \"Hi, I\\'m Bob\"s already! Let\\'s try to break the ice, shall we? I\\'ll ask you a question: What\\'s your favorite thing to do on a sunny Saturday morning?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 178, 'total_tokens': 233, 'completion_time': 0.045833333, 'prompt_time': 0.033581494, 'queue_time': 0.05265800999999999, 'total_time': 0.079414827}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-8f239344-43c1-416c-aecc-bbd5a7ee1fde-0', usage_metadata={'input_tokens': 178, 'output_tokens': 55, 'total_tokens': 233}),\n",
              " HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='aa29235c-18aa-4bc6-94d3-43f17f0b500a'),\n",
              " AIMessage(content=\"Your name is Bob! You've told me that several times already!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 247, 'total_tokens': 262, 'completion_time': 0.0125, 'prompt_time': 0.046338946, 'queue_time': 0.04380124800000001, 'total_time': 0.058838946}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-52452534-00c8-45ad-a552-34b5fdf36a1b-0', usage_metadata={'input_tokens': 247, 'output_tokens': 15, 'total_tokens': 262})]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e_m9WGBu_ENM",
        "outputId": "a733ea1f-7bd3-4c73-8115-a38cb7f85fe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Your name is Bob! You've told me that several times already!\n"
          ]
        }
      ],
      "source": [
        "query = \"What's my name?\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YpffL1A_ENN"
      },
      "source": [
        "Great! Our chatbot now remembers things about us. If we change the config to reference a different `thread_id`, we can see that it starts the conversation fresh.\n",
        "\n",
        "太棒了！我们的聊天机器人现在能记住关于我们的事情了。如果我们更改配置以引用不同的 thread_id ，我们就可以看到它从头开始新的对话。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VXw-Wot3_ENN",
        "outputId": "b6465ced-81ec-4342-a726-0f33cd4ddc75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I apologize, but I'm a large language model, I don't have the ability to know your personal information, including your name. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations.\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8xfQfax_ENN"
      },
      "source": [
        "然而，我们总是可以回到原始对话（因为我们将其保存在数据库中）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bjkltGnQ_ENN",
        "outputId": "5cc08b35-36f2-4f4e-f06d-98cc1d2bbbab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I think I've already told you, Bob... Your name is Bob!\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d0OWPsr_ENN"
      },
      "source": [
        "这是我们可以支持聊天机器人与许多用户进行对话的方式！\n",
        "\n",
        ":::tip 提示\n",
        "\n",
        "For async support, update the `call_model` node to be an async function and use `.ainvoke` when invoking the application:\n",
        "\n",
        "为支持异步，将 call_model 节点更新为异步函数，并在调用应用程序时使用 .ainvoke ：\n",
        "\n",
        "```python\n",
        "# Async function for node:\n",
        "async def call_model(state: MessagesState):\n",
        "    response = await model.ainvoke(state[\"messages\"])\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "# Define graph as before:\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "app = workflow.compile(checkpointer=MemorySaver())\n",
        "\n",
        "# Async invocation:\n",
        "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()\n",
        "```\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B67EoY8I_ENN"
      },
      "source": [
        "目前，我们只是在模型周围添加了一个简单的持久化层。我们可以通过添加提示模板来使聊天机器人更加复杂和个性化。\n",
        "\n",
        "## Prompt templates提示模板\n",
        "\n",
        "[Prompt Templates](/docs/concepts/prompt_templates) help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages.\n",
        "\n",
        "提示模板有助于将原始用户信息转换为LLM可以处理的形式。在这种情况下，原始用户输入只是一个消息，我们将其传递给LLM。现在让我们使它变得更加复杂。首先，让我们添加一个包含一些自定义指令的系统消息（但仍然以消息为输入）。接下来，我们将添加更多输入，而不仅仅是消息。\n",
        "\n",
        "To add in a system message, we will create a `ChatPromptTemplate`. We will utilize `MessagesPlaceholder` to pass all the messages in.\n",
        "\n",
        "添加系统消息时，我们将创建一个 ChatPromptTemplate 。我们将使用 MessagesPlaceholder 来传递所有消息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yru45yfh_ENN"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtZ_Kw0y_ENN"
      },
      "source": [
        "我们现在可以更新我们的应用程序以包含此模板："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7Ri8XfYN_ENO"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "\n",
        "def call_model(state: MessagesState):\n",
        "    # highlight-start\n",
        "    prompt = prompt_template.invoke(state)\n",
        "    response = model.invoke(prompt)\n",
        "    # highlight-end\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzWaH4jP_ENO"
      },
      "source": [
        "我们以相同的方式调用应用程序："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rc49TGuJ_ENO",
        "outputId": "113fcd9d-0ad4-4faf-d6af-224850383e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Arrrr, shiver me timbers! 'Tis a pleasure to make yer acquaintance, Jim! What be bringin' ye to these fair waters?\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
        "query = \"Hi! I'm Jim.\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wBNDIQ7f_ENO",
        "outputId": "e3868068-0f4a-472f-fafd-190c0f4352d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Shiver me spyglass! Ye be askin' me what yer name be again, matey? Aye, I'll tell ye again, yer name be Jim! Yer a lucky buccaneer to have such a fine moniker, savvy?\n"
          ]
        }
      ],
      "source": [
        "query = \"What is my name?\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_p7Ut0r_ENO"
      },
      "source": [
        "太棒了！现在让我们使我们的提示变得更加复杂。假设提示模板现在看起来像这样："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PEVZdChZ_ENO"
      },
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysCw3Fr4_ENO"
      },
      "source": [
        "Note that we have added a new `language` input to the prompt. Our application now has two parameters-- the input `messages` and `language`. We should update our application's state to reflect this:\n",
        "\n",
        "请注意，我们在提示中添加了一个新的 language 输入。我们的应用程序现在有两个参数--输入 messages 和 language 。我们应该更新应用程序的状态以反映这一点："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pb__oQu9_ENP"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "\n",
        "# highlight-next-line\n",
        "class State(TypedDict):\n",
        "    # highlight-next-line\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "    # highlight-next-line\n",
        "    language: str\n",
        "\n",
        "\n",
        "workflow = StateGraph(state_schema=State)\n",
        "\n",
        "\n",
        "def call_model(state: State):\n",
        "    prompt = prompt_template.invoke(state)\n",
        "    response = model.invoke(prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H5ROknVx_ENP",
        "outputId": "9295df12-a3b5-4e03-c784-8baf438e81d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hola Bob! ¡Bienvenido! ¿En qué puedo ayudarte hoy? (Hello Bob! Welcome! How can I help you today?)\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
        "query = \"Hi! I'm Bob.\"\n",
        "language = \"Spanish\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke(\n",
        "    # highlight-next-line\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        ")\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZDe3b7n_ENP"
      },
      "source": [
        "Note that the entire state is persisted, so we can omit parameters like `language` if no changes are desired:\n",
        "\n",
        "请注意，整个状态都会被持久化，因此如果不想进行任何更改，我们可以省略如 language 这样的参数："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ohRD_z-K_ENP",
        "outputId": "03298c6f-e0b3-4dff-f900-dc36000177b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡Ah! Tu nombre es Bob, ¿correcto? (Ah! Your name is Bob, correct?)\n"
          ]
        }
      ],
      "source": [
        "query = \"What is my name?\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke(\n",
        "    {\"messages\": input_messages},\n",
        "    config,\n",
        ")\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ3W6YAQ_ENP"
      },
      "source": [
        "To help you understand what's happening internally, check out [this LangSmith trace](https://smith.langchain.com/public/15bd8589-005c-4812-b9b9-23e74ba4c3c6/r)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpSV9eri_ENP"
      },
      "source": [
        "## Managing Conversation History管理对话历史\n",
        "\n",
        "构建聊天机器人时，理解如何管理对话历史是一个重要的概念。如果未进行管理，消息列表将无限增长，并可能超出LLM的上下文窗口。因此，添加一个限制传递消息大小的步骤非常重要。\n",
        "\n",
        "**Importantly, you will want to do this BEFORE the prompt template but AFTER you load previous messages from Message History.**\n",
        "\n",
        "重要地，您需要在提示模板之前，但在从消息历史记录中加载之前的消息之后执行此操作。\n",
        "\n",
        "We can do this by adding a simple step in front of the prompt that modifies the `messages` key appropriately, and then wrap that new chain in the Message History class.\n",
        "\n",
        "我们可以通过在提示符前添加一个简单的步骤来适当地修改 messages 键，然后将这个新链包装在消息历史类中来实现这一点。\n",
        "\n",
        "LangChain comes with a few built-in helpers for [managing a list of messages](/docs/how_to/#messages). In this case we'll use the [trim_messages](/docs/how_to/trim_messages/) helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages:\n",
        "\n",
        "LangChain 自带一些内置助手来管理消息列表。在这种情况下，我们将使用 trim_messages 助手来减少发送给模型的短信数量。修剪器允许我们指定要保留多少个令牌，以及其他参数，例如是否始终保留系统消息以及是否允许部分消息："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9bl6nt8J_ENT",
        "outputId": "8f472d44-305f-4cf8-88ce-b47ab98a2336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504,
          "referenced_widgets": [
            "f57b21bf8a1544449b4e654e3cc27f1e",
            "74d9025c5c554d53a3171f492230a866",
            "a23c9f85a9cd482d954df1db03a00859",
            "d155ec27ce104bd688a34f8bd77e9b7a",
            "19ae3dd271bd4b608aaa9830b1665590",
            "e5f320cfd27a48f39f971dea13b17492",
            "64cb75f766264fcd814b1ca06747c2e2",
            "bdb68f5c72e549428d80a9c7e5a2eb38",
            "c2fe906e6e2b40c5814cfbd45e88ec5d",
            "cb1b6426ddc24ef89fbd0fea9ea31f1e",
            "7cda2f83193d4e05a2fd7a6767e5e760",
            "6982f40eed47421c83be2f44dc6f24e8",
            "bf10d420082945869dbf1e4d8ad184ce",
            "b9bc363c7ac949fcb9ff069b9f14a588",
            "95290b44d2464ec4846f51047e639d3b",
            "0e21c4e8549746ceb82a4db3ddf6dcae",
            "6ad3d0abaecf4346903c37aa8800ced6",
            "3351ff1208454a939427da097b4e20b7",
            "da749103753c437581a55d7abe994e55",
            "95e7a669cd9d4a5da12dbcecfd8d7695",
            "2db9fea30b194f6aa5b5c1385f724866",
            "1ab4637fe7554345afc7f51fc67112bf",
            "33c69e1cac3841c78e434f7d0aa4ed95",
            "6015c33ac3664e3eb3bc9a3d8bcbf1e2",
            "0ba62ee4a1d8430b95e6923c6506de22",
            "22c7a80eb8e94011bb75b7e00df6758e",
            "4d1b8475d3b84aaea0effa71941d7bf5",
            "7ee94c5f8de741359c280c85cd7fceff",
            "ff711fa18cb045b7b60eb3f952876444",
            "2d68b589514542f39e6b0109e341650c",
            "12e8e097ff864014b3ce45a71bc2b072",
            "b82f0ea0120b49a9822fb4ddb859e0bb",
            "a23883e35a4844d39c5ada89fa0ca8df",
            "428e161e01ec41649d320fdd37413383",
            "1fc1f2e6b8f44d94b538767e5dc06a75",
            "24ed0263142347a6ab4140df15d2f2c0",
            "b8fe5f8681194fbdbceefe9d0b6a8c78",
            "f54cf58e0fb9470c900375f39a0db473",
            "1295839742a44fec90328781a0b97c0b",
            "f92322f3954b459d91dbcbed7e33c543",
            "27daea8016c3402bb4a2533b843a8eea",
            "e6761584c0c24d658f05f6ee1508903d",
            "caeffe762940425c8f04ac9b48b55c19",
            "0ede1cc6af4646d1967836378be5df6f",
            "a0141fc5c78d4e709a8556ec34f7a7ca",
            "4809a9bf313f412b8fff79f8c1e0fba2",
            "055130b541344946933e11846205e921",
            "dd2ab11c113e457f86f493b0bfbbbbc7",
            "4ab26bbc594746008b8006808e1e98fb",
            "e787fd65eaf64b55b44e487b9601dbe2",
            "8ed83da85a894aeebec52b061b9a4ec8",
            "0c7cbf02911145eb8d4818f7b901adf6",
            "9c4e04069022499083626244cd64ec42",
            "33ef2c692c9e42d991f94815c007d0dc",
            "688f0ccd3e6d4bdea7defa43ad4aa17c"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f57b21bf8a1544449b4e654e3cc27f1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6982f40eed47421c83be2f44dc6f24e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33c69e1cac3841c78e434f7d0aa4ed95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "428e161e01ec41649d320fdd37413383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0141fc5c78d4e709a8556ec34f7a7ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from langchain_core.messages import SystemMessage, trim_messages\n",
        "\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=65,\n",
        "    strategy=\"last\",\n",
        "    token_counter=model,\n",
        "    include_system=True,\n",
        "    allow_partial=False,\n",
        "    start_on=\"human\",\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"you're a good assistant\"),\n",
        "    HumanMessage(content=\"hi! I'm bob\"),\n",
        "    AIMessage(content=\"hi!\"),\n",
        "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
        "    AIMessage(content=\"nice\"),\n",
        "    HumanMessage(content=\"whats 2 + 2\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "    HumanMessage(content=\"thanks\"),\n",
        "    AIMessage(content=\"no problem!\"),\n",
        "    HumanMessage(content=\"having fun?\"),\n",
        "    AIMessage(content=\"yes!\"),\n",
        "]\n",
        "\n",
        "trimmer.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsieYTJm_ENU"
      },
      "source": [
        "To  use it in our chain, we just need to run the trimmer before we pass the `messages` input to our prompt.\n",
        "\n",
        "在将输入传递到我们的提示之前，我们只需在它之前运行修剪器即可。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-C_Zsseu_ENU"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(state_schema=State)\n",
        "\n",
        "\n",
        "def call_model(state: State):\n",
        "    # highlight-start\n",
        "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
        "    prompt = prompt_template.invoke(\n",
        "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n",
        "    )\n",
        "    response = model.invoke(prompt)\n",
        "    # highlight-end\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WotFPxje_ENU"
      },
      "source": [
        "现在如果我们尝试询问模型我们的名字，它不会知道，因为我们已经剪掉了聊天记录中的那部分："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Ngn1060W_ENU",
        "outputId": "9394c393-b8a3-4253-818a-f8002242d261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Your name is Bob!\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
        "query = \"What is my name?\"\n",
        "language = \"English\"\n",
        "\n",
        "# highlight-next-line\n",
        "input_messages = messages + [HumanMessage(query)]\n",
        "output = app.invoke(\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        ")\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0cyY8cO_ENU"
      },
      "source": [
        "但是如果我们询问关于最后几条消息中的信息，它会记住："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XIxbkWYS_ENU",
        "outputId": "f61ea4a4-0f76-406f-cba5-cbc6f38bcd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "You asked me what 2 + 2 is!\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n",
        "query = \"What math problem did I ask?\"\n",
        "language = \"English\"\n",
        "\n",
        "input_messages = messages + [HumanMessage(query)]\n",
        "output = app.invoke(\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        ")\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLhv2dzM_ENV"
      },
      "source": [
        "If you take a look at LangSmith, you can see exactly what is happening under the hood in the [LangSmith trace](https://smith.langchain.com/public/04402eaa-29e6-4bb1-aa91-885b730b6c21/r).\n",
        "\n",
        "如果您查看 LangSmith，您可以看到 LangSmith 跟踪中底层的具体发生情况。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7Pq3_pF_ENV"
      },
      "source": [
        "## Streaming流媒体\n",
        "\n",
        "现在我们有一个功能齐全的聊天机器人。然而，对于聊天机器人应用来说，用户体验的一个重要考虑因素是流式传输。LLMs有时需要一些时间才能响应，因此为了提高用户体验，大多数应用会以流式传输的方式逐个返回生成的每个标记。这使用户能够看到进度。\n",
        "\n",
        "实际上做这件事超级简单！\n",
        "\n",
        "By default, `.stream` in our LangGraph application streams application steps-- in this case, the single step of the model response. Setting `stream_mode=\"messages\"` allows us to stream output tokens instead:\n",
        "\n",
        "默认情况下，在 LangGraph 应用程序中， .stream 流式传输应用程序步骤--在这种情况下，是模型响应的单个步骤。设置 stream_mode=\"messages\" 允许我们流式传输输出标记："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "e9qjcmIr_ENV",
        "outputId": "3776e391-94d3-4a64-8b0a-a1c44f783c05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|Hi| Todd|!| Here|'s| one|:\n",
            "\n",
            "|Why| couldn|'t| the| bicycle| stand| up| by| itself|?\n",
            "\n",
            "|(wait| for| it|...)\n",
            "\n",
            "|Because| it| was| two|-t|ired|!\n",
            "\n",
            "|Hope| that| made| you| smile|!| Do| you| want| to| hear| another| one|?||"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
        "query = \"Hi I'm Todd, please tell me a joke.\"\n",
        "language = \"English\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "# highlight-next-line\n",
        "for chunk, metadata in app.stream(\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        "    # highlight-next-line\n",
        "    stream_mode=\"messages\",\n",
        "):\n",
        "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
        "        print(chunk.content, end=\"|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YgHF8F__ENV"
      },
      "source": [
        "## Next Steps下一步\n",
        "\n",
        "现在你已经了解了如何在 LangChain 中创建聊天机器人的基础知识，以下是一些你可能感兴趣的更高级教程：\n",
        "\n",
        "- [Conversational RAG](/docs/tutorials/qa_chat_history): Enable a chatbot experience over an external source of data\n",
        "- [Agents](/docs/tutorials/agents): Build a chatbot that can take actions\n",
        "\n",
        "如果您想深入了解具体细节，以下是一些值得检查的内容：\n",
        "\n",
        "- [Streaming](/docs/how_to/streaming): streaming is *crucial* for chat applications\n",
        "- [How to add message history](/docs/how_to/message_history): for a deeper dive into all things related to message history\n",
        "- [How to manage large message history](/docs/how_to/trim_messages/): more techniques for managing a large chat history\n",
        "- [LangGraph main docs](https://langchain-ai.github.io/langgraph/): for more detail on building with LangGraph"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f57b21bf8a1544449b4e654e3cc27f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74d9025c5c554d53a3171f492230a866",
              "IPY_MODEL_a23c9f85a9cd482d954df1db03a00859",
              "IPY_MODEL_d155ec27ce104bd688a34f8bd77e9b7a"
            ],
            "layout": "IPY_MODEL_19ae3dd271bd4b608aaa9830b1665590"
          }
        },
        "74d9025c5c554d53a3171f492230a866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f320cfd27a48f39f971dea13b17492",
            "placeholder": "​",
            "style": "IPY_MODEL_64cb75f766264fcd814b1ca06747c2e2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a23c9f85a9cd482d954df1db03a00859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb68f5c72e549428d80a9c7e5a2eb38",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2fe906e6e2b40c5814cfbd45e88ec5d",
            "value": 26
          }
        },
        "d155ec27ce104bd688a34f8bd77e9b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb1b6426ddc24ef89fbd0fea9ea31f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_7cda2f83193d4e05a2fd7a6767e5e760",
            "value": " 26.0/26.0 [00:00&lt;00:00, 997B/s]"
          }
        },
        "19ae3dd271bd4b608aaa9830b1665590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f320cfd27a48f39f971dea13b17492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64cb75f766264fcd814b1ca06747c2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdb68f5c72e549428d80a9c7e5a2eb38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2fe906e6e2b40c5814cfbd45e88ec5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb1b6426ddc24ef89fbd0fea9ea31f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cda2f83193d4e05a2fd7a6767e5e760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6982f40eed47421c83be2f44dc6f24e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf10d420082945869dbf1e4d8ad184ce",
              "IPY_MODEL_b9bc363c7ac949fcb9ff069b9f14a588",
              "IPY_MODEL_95290b44d2464ec4846f51047e639d3b"
            ],
            "layout": "IPY_MODEL_0e21c4e8549746ceb82a4db3ddf6dcae"
          }
        },
        "bf10d420082945869dbf1e4d8ad184ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad3d0abaecf4346903c37aa8800ced6",
            "placeholder": "​",
            "style": "IPY_MODEL_3351ff1208454a939427da097b4e20b7",
            "value": "vocab.json: 100%"
          }
        },
        "b9bc363c7ac949fcb9ff069b9f14a588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da749103753c437581a55d7abe994e55",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95e7a669cd9d4a5da12dbcecfd8d7695",
            "value": 1042301
          }
        },
        "95290b44d2464ec4846f51047e639d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2db9fea30b194f6aa5b5c1385f724866",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab4637fe7554345afc7f51fc67112bf",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.69MB/s]"
          }
        },
        "0e21c4e8549746ceb82a4db3ddf6dcae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad3d0abaecf4346903c37aa8800ced6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3351ff1208454a939427da097b4e20b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da749103753c437581a55d7abe994e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e7a669cd9d4a5da12dbcecfd8d7695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2db9fea30b194f6aa5b5c1385f724866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab4637fe7554345afc7f51fc67112bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33c69e1cac3841c78e434f7d0aa4ed95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6015c33ac3664e3eb3bc9a3d8bcbf1e2",
              "IPY_MODEL_0ba62ee4a1d8430b95e6923c6506de22",
              "IPY_MODEL_22c7a80eb8e94011bb75b7e00df6758e"
            ],
            "layout": "IPY_MODEL_4d1b8475d3b84aaea0effa71941d7bf5"
          }
        },
        "6015c33ac3664e3eb3bc9a3d8bcbf1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ee94c5f8de741359c280c85cd7fceff",
            "placeholder": "​",
            "style": "IPY_MODEL_ff711fa18cb045b7b60eb3f952876444",
            "value": "merges.txt: 100%"
          }
        },
        "0ba62ee4a1d8430b95e6923c6506de22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d68b589514542f39e6b0109e341650c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12e8e097ff864014b3ce45a71bc2b072",
            "value": 456318
          }
        },
        "22c7a80eb8e94011bb75b7e00df6758e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b82f0ea0120b49a9822fb4ddb859e0bb",
            "placeholder": "​",
            "style": "IPY_MODEL_a23883e35a4844d39c5ada89fa0ca8df",
            "value": " 456k/456k [00:00&lt;00:00, 2.23MB/s]"
          }
        },
        "4d1b8475d3b84aaea0effa71941d7bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ee94c5f8de741359c280c85cd7fceff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff711fa18cb045b7b60eb3f952876444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d68b589514542f39e6b0109e341650c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e8e097ff864014b3ce45a71bc2b072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b82f0ea0120b49a9822fb4ddb859e0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23883e35a4844d39c5ada89fa0ca8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "428e161e01ec41649d320fdd37413383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fc1f2e6b8f44d94b538767e5dc06a75",
              "IPY_MODEL_24ed0263142347a6ab4140df15d2f2c0",
              "IPY_MODEL_b8fe5f8681194fbdbceefe9d0b6a8c78"
            ],
            "layout": "IPY_MODEL_f54cf58e0fb9470c900375f39a0db473"
          }
        },
        "1fc1f2e6b8f44d94b538767e5dc06a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1295839742a44fec90328781a0b97c0b",
            "placeholder": "​",
            "style": "IPY_MODEL_f92322f3954b459d91dbcbed7e33c543",
            "value": "tokenizer.json: 100%"
          }
        },
        "24ed0263142347a6ab4140df15d2f2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27daea8016c3402bb4a2533b843a8eea",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6761584c0c24d658f05f6ee1508903d",
            "value": 1355256
          }
        },
        "b8fe5f8681194fbdbceefe9d0b6a8c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caeffe762940425c8f04ac9b48b55c19",
            "placeholder": "​",
            "style": "IPY_MODEL_0ede1cc6af4646d1967836378be5df6f",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.17MB/s]"
          }
        },
        "f54cf58e0fb9470c900375f39a0db473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1295839742a44fec90328781a0b97c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92322f3954b459d91dbcbed7e33c543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27daea8016c3402bb4a2533b843a8eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6761584c0c24d658f05f6ee1508903d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "caeffe762940425c8f04ac9b48b55c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ede1cc6af4646d1967836378be5df6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0141fc5c78d4e709a8556ec34f7a7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4809a9bf313f412b8fff79f8c1e0fba2",
              "IPY_MODEL_055130b541344946933e11846205e921",
              "IPY_MODEL_dd2ab11c113e457f86f493b0bfbbbbc7"
            ],
            "layout": "IPY_MODEL_4ab26bbc594746008b8006808e1e98fb"
          }
        },
        "4809a9bf313f412b8fff79f8c1e0fba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e787fd65eaf64b55b44e487b9601dbe2",
            "placeholder": "​",
            "style": "IPY_MODEL_8ed83da85a894aeebec52b061b9a4ec8",
            "value": "config.json: 100%"
          }
        },
        "055130b541344946933e11846205e921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c7cbf02911145eb8d4818f7b901adf6",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c4e04069022499083626244cd64ec42",
            "value": 665
          }
        },
        "dd2ab11c113e457f86f493b0bfbbbbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ef2c692c9e42d991f94815c007d0dc",
            "placeholder": "​",
            "style": "IPY_MODEL_688f0ccd3e6d4bdea7defa43ad4aa17c",
            "value": " 665/665 [00:00&lt;00:00, 56.3kB/s]"
          }
        },
        "4ab26bbc594746008b8006808e1e98fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e787fd65eaf64b55b44e487b9601dbe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed83da85a894aeebec52b061b9a4ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c7cbf02911145eb8d4818f7b901adf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c4e04069022499083626244cd64ec42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33ef2c692c9e42d991f94815c007d0dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688f0ccd3e6d4bdea7defa43ad4aa17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}